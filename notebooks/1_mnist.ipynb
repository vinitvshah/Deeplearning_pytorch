{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfba6c5",
      "metadata": {
        "id": "bdfba6c5"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb4a334",
      "metadata": {
        "id": "deb4a334",
        "outputId": "06130095-9ec7-4aab-c304-c228bd878968"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x103bfd990>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f54d472",
      "metadata": {
        "id": "5f54d472"
      },
      "outputs": [],
      "source": [
        "# input layer, a single hidden layer, and an output layer\n",
        "# Define hyperparameters\n",
        "input_size = 784  # 28x28 pixels\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "#tip to choose to size of hidden layer\n",
        "#There is no thumb rule however hidden layers depend numbers of feature it has to learn, you can start with 1 and optimize and move forward.\n",
        "\n",
        "batch_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf93c989",
      "metadata": {
        "id": "cf93c989"
      },
      "outputs": [],
      "source": [
        "img = torchvision.datasets.MNIST(root='../data', train=True, download=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de01bf4",
      "metadata": {
        "id": "0de01bf4"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),   # convert to pytorch tensor\n",
        "     transforms.Normalize((0.1307,), (0.3081,))]  # standardize the values with mean + std\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='../data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e926a88c",
      "metadata": {
        "id": "e926a88c",
        "outputId": "2bc3c89d-fdc0-4420-e3d1-0306ce66bf1e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# transpose the array to (28, 28) format expected by Matplotlib\n",
        "array = np.squeeze(np.transpose(train_dataset[0][0], (1, 2, 0)))\n",
        "\n",
        "# plot the image using Matplotlib\n",
        "plt.imshow(array)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f64815",
      "metadata": {
        "id": "42f64815",
        "outputId": "cb5f667d-2d6a-46ce-a293-419953846292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(test_loader))[0].shape # we have 100 images with 1,28,28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef55b65",
      "metadata": {
        "id": "9ef55b65"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU() #most common activation function with GPT \n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Create the model\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca379b3",
      "metadata": {
        "id": "fca379b3"
      },
      "outputs": [],
      "source": [
        "# Loss function options\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "nll_loss = nn.NLLLoss()\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502faaf8",
      "metadata": {
        "id": "502faaf8"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train_model(model, loss_function, train_loader, optimizer, num_epochs=10):\n",
        "    # Put the model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Iterate over the number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Initialize the running loss for this epoch to zero\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # Iterate over each batch in the training loader\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            \n",
        "            # Reshape the images tensor to have size (batch_size, input_size)\n",
        "            images = images.reshape(-1, input_size)\n",
        "            # Forward pass: compute the outputs of the model given the input images\n",
        "            outputs = model(images)\n",
        "            # Compute the loss between the outputs and the true labels\n",
        "            loss = loss_function(outputs, labels)\n",
        "            # Backward pass: compute the gradients of the loss with respect to the model parameters\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # Update the model parameters using the optimizer\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Add the current batch loss to the running loss for this epoch\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Compute the average loss over all batches for this epoch and print it\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410c88bf",
      "metadata": {
        "id": "410c88bf"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_loader):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Initialize empty lists to store true and predicted labels\n",
        "    y_true, y_pred = [], []\n",
        "    \n",
        "    # Disable gradient computation since we're only evaluating the model\n",
        "    with torch.no_grad():\n",
        "        # Iterate over each batch in the test loader\n",
        "        for images, labels in test_loader:\n",
        "            # Reshape the images tensor to have size (batch_size, input_size)\n",
        "            images = images.reshape(-1, input_size)\n",
        "            \n",
        "            # Forward pass: compute the outputs of the model given the input images\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # Find the predicted class for each image in the batch\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Append the true and predicted labels for this batch to the lists\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(predicted.numpy())\n",
        "    \n",
        "    # Calculate evaluation metrics using the true and predicted labels\n",
        "    accuracy, f1, precision, recall = evaluate_model_metrics(np.array(y_true), np.array(y_pred))\n",
        "    \n",
        "    # Return the evaluation metrics\n",
        "    return accuracy, f1, precision, recall\n",
        "\n",
        "# Function to calculate evaluation metrics\n",
        "def evaluate_model_metrics(y_true, y_pred):\n",
        "    # Compute the accuracy, F1 score, precision, and recall\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # Return the evaluation metrics\n",
        "    return accuracy, f1, precision, recall\n",
        "\n",
        "# Define a dictionary of loss functions\n",
        "loss_functions = {\n",
        "    'CrossEntropyLoss': nn.CrossEntropyLoss(),\n",
        "    'NLLLoss': nn.NLLLoss(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f155c68d",
      "metadata": {
        "id": "f155c68d",
        "outputId": "121647fe-4234-4434-8ba3-3ac32fa76355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with CrossEntropyLoss:\n",
            "Epoch [1/10], Loss: 0.2845\n",
            "Epoch [2/10], Loss: 0.1248\n",
            "Epoch [3/10], Loss: 0.0850\n",
            "Epoch [4/10], Loss: 0.0631\n",
            "Epoch [5/10], Loss: 0.0513\n",
            "Epoch [6/10], Loss: 0.0399\n",
            "Epoch [7/10], Loss: 0.0323\n",
            "Epoch [8/10], Loss: 0.0272\n",
            "Epoch [9/10], Loss: 0.0225\n",
            "Epoch [10/10], Loss: 0.0220\n",
            "Performance metrics for CrossEntropyLoss:\n",
            "Accuracy: 0.9767, F1-score: 0.9766, Precision: 0.9766, Recall: 0.9767\n",
            "\n",
            "Training with NLLLoss:\n",
            "Epoch [1/10], Loss: -11812.1983\n",
            "Epoch [2/10], Loss: -84332.6273\n",
            "Epoch [3/10], Loss: -219235.6355\n",
            "Epoch [4/10], Loss: -405894.0463\n",
            "Epoch [5/10], Loss: -638261.7497\n",
            "Epoch [6/10], Loss: -911766.3699\n",
            "Epoch [7/10], Loss: -1222908.0429\n",
            "Epoch [8/10], Loss: -1569687.2360\n",
            "Epoch [9/10], Loss: -1950855.6594\n",
            "Epoch [10/10], Loss: -2365668.1362\n",
            "Performance metrics for NLLLoss:\n",
            "Accuracy: 0.1135, F1-score: 0.0204, Precision: 0.0114, Recall: 0.1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the model using different loss functions\n",
        "for loss_name, loss_function in loss_functions.items():\n",
        "    print(f'Training with {loss_name}:')\n",
        "    \n",
        "    # Initialize a new model and optimizer for each loss function\n",
        "    model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Train the model\n",
        "    train_model(model, loss_function, train_loader, optimizer, num_epochs=10)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, f1, precision, recall = evaluate_model(model, test_loader)\n",
        "    print(f'Performance metrics for {loss_name}:')\n",
        "    print(f'Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d641f72",
      "metadata": {
        "id": "1d641f72"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}